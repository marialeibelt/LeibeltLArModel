{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0beb0548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from pathlib import Path\n",
    "import scipy.constants as sc\n",
    "from math import pi\n",
    "import scipy.integrate as integrate\n",
    "import sympy as sp\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import uproot\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00d6f986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting functions\n",
    "def OnePlot(xlabel,ylabel,xscale,yscale,nxaxis,xlabel_secondary,xscale_secondary,Savename):\n",
    "    ax1.grid(True,alpha=0.7,ls='dotted')\n",
    "    ax1.legend(fontsize = 9)\n",
    "    ax1.set_xlabel(xlabel, fontsize=9)\n",
    "    ax1.set_ylabel(ylabel,fontsize=9)\n",
    "    if xscale == \"log\":\n",
    "        ax1.set_xscale(\"log\")\n",
    "    if yscale == \"log\":\n",
    "        ax1.set_yscale(\"log\")\n",
    "    if nxaxis == 2:\n",
    "        ax1_secondary = ax1.twiny()\n",
    "        ax1_secondary.set_xlabel(xlabel_secondary, fontsize=9)\n",
    "        xlim1_secondary = secondary_xaxis_transform(np.array(ax1.get_xlim()))\n",
    "        ax1_secondary.set_xlim(xlim1_secondary)\n",
    "    if xscale_secondary == \"log\":\n",
    "        ax1_secondary.set_xscale(\"log\")\n",
    "    plt.rcParams.update({'font.size': 7, 'font.family' : 'serif'})\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(\"C:/Users/maria/Documents/Uni/Bachelorarbeit/Coden/Leibelt_Bilder/\" + Savename + \".pdf\", bbox_inches = \"tight\")\n",
    "    fig.savefig(\"C:/Users/maria/Documents/Uni/Bachelorarbeit/Coden/Leibelt_Bilder/\" + Savename + \".png\", dpi=700, bbox_inches = \"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "def TwoPlots(xlabel1,ylabel1,xscale1,yscale1,nxaxis1,xlabel_secondary1,xscale1_secondary,xlabel2,ylabel2,xscale2,yscale2,nxaxis2,xlabel_secondary2,xscale2_secondary,Savename):\n",
    "    ax1.grid(True,alpha=0.7,ls='dotted')\n",
    "    # ax1.legend(fontsize = 9)\n",
    "    ax1.set_xlabel(xlabel1, fontsize=9)\n",
    "    ax1.set_ylabel(ylabel1,fontsize=9)\n",
    "    ax2.grid(True,alpha=0.7,ls='dotted')\n",
    "    # ax2.legend(fontsize = 9)\n",
    "    ax2.set_xlabel(xlabel2, fontsize=9)\n",
    "    ax2.set_ylabel(ylabel2,fontsize=9)\n",
    "    if xscale1 == \"log\":\n",
    "        ax1.set_xscale(\"log\")\n",
    "    if yscale1 == \"log\":\n",
    "        ax1.set_yscale(\"log\")\n",
    "    if xscale2 == \"log\":\n",
    "        ax2.set_xscale(\"log\")\n",
    "    if yscale2 == \"log\":\n",
    "        ax2.set_yscale(\"log\")\n",
    "    if nxaxis1 == 2:\n",
    "        ax1_secondary = ax1.twiny()\n",
    "        ax1_secondary.set_xlabel(xlabel_secondary1, fontsize=9)\n",
    "        xlim1_secondary = secondary_xaxis_transform(np.array(ax1.get_xlim()))\n",
    "        ax1_secondary.set_xlim(xlim1_secondary)\n",
    "        \n",
    "    if nxaxis2 == 2:\n",
    "        ax2_secondary = ax2.twiny()\n",
    "        ax2_secondary.set_xlabel(xlabel_secondary2, fontsize=9)\n",
    "        xlim2_secondary = secondary_xaxis_transform(np.array(ax2.get_xlim()))\n",
    "        ax2_secondary.set_xlim(xlim2_secondary)\n",
    "\n",
    "    if xscale1_secondary == \"log\":\n",
    "        ax1_secondary.set_xscale(\"log\")\n",
    "    if xscale2_secondary == \"log\":\n",
    "        ax2_secondary.set_xscale(\"log\")\n",
    "\n",
    "    plt.rcParams.update({'font.size': 7, 'font.family' : 'serif'})\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(\"C:/Users/maria/Documents/Uni/Bachelorarbeit/Coden/Leibelt_Bilder/\" + Savename + \".pdf\", bbox_inches = \"tight\")\n",
    "    fig.savefig(\"C:/Users/maria/Documents/Uni/Bachelorarbeit/Coden/Leibelt_Bilder/\" + Savename + \".png\", dpi=700, bbox_inches = \"tight\")\n",
    "    plt.show()\n",
    "\n",
    "def secondary_xaxis_transform(x):\n",
    "    return x * 3.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a103e47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define used functions\n",
    "\n",
    "#photon arrival time spectra\n",
    "def l(t,A,kx,kxM,Type,Ntot,kI):\n",
    "    NS = constants[\"sfrac\"]*Ntot\n",
    "    NT = (1-constants[\"sfrac\"])*Ntot\n",
    "    CS= A/constants[\"tauS\"] + kx\n",
    "    CT = A/constants[\"tauT\"] + kx\n",
    "    lambdaM = 1/constants[\"tauM\"] + kxM + constants[\"kqM\"] + kI\n",
    "    lambdaS = 1/constants[\"tauS\"] + kx + constants[\"kqS\"] + kI\n",
    "    lambdaT = 1/constants[\"tauT\"] + kx + constants[\"kqT\"] + kI\n",
    "    lambdaX = 1/constants[\"tauX\"] + constants[\"kqX\"] + kI\n",
    "\n",
    "    \n",
    "    l1 = (NS * (1-A) / constants[\"tauS\"]) * np.exp(-t*lambdaS)\n",
    "    \n",
    "    l2 = (NT * (1-A) / constants[\"tauT\"]) * np.exp(-t*lambdaT)\n",
    "    \n",
    "    M1 = NS*CS/(lambdaS-lambdaM) * (np.exp(-t*lambdaM)-np.exp(-t*lambdaS))\n",
    "    M3 = NT*CT/(lambdaT-lambdaM) * (np.exp(-t*lambdaM)-np.exp(-t*lambdaT))\n",
    "    M = M1 + M3\n",
    "    l3 = M/constants[\"tauM\"]\n",
    "    \n",
    "    X1 = NS*CS*kx/(lambdaS-lambdaM) * ( (np.exp(-t*lambdaM)-np.exp(-t*lambdaX))/(lambdaX-lambdaM) - (np.exp(-t*lambdaS)-np.exp(-t*lambdaX))/(lambdaX-lambdaS) )\n",
    "    X3 = NT*CT*kx/(lambdaT-lambdaM) * ( (np.exp(-t*lambdaM)-np.exp(-t*lambdaX))/(lambdaX-lambdaM) - (np.exp(-t*lambdaT)-np.exp(-t*lambdaX))/(lambdaX-lambdaT) )\n",
    "    X = X1 + X3\n",
    "    l4 = X/constants[\"tauX\"]\n",
    "    \n",
    "    if Type == \"S\":\n",
    "        l = l1  \n",
    "    if Type == \"T\":\n",
    "        l = l2    \n",
    "    if Type == \"M\":\n",
    "        l = l3 \n",
    "    if  Type == \"X\":\n",
    "        l = l4\n",
    "    if Type == \"All\":\n",
    "        l = l1 + l2 + l3 + l4\n",
    "    \n",
    "    return l\n",
    "\n",
    "\n",
    "#Light yield: photon arrival time spectra integrated from 0-infinity\n",
    "def Lxe(xecon,Type,Distance,Ntot,kI,kx):\n",
    "    kxM = kx\n",
    "\n",
    "    lambda1fit = 12.69 * 0.1/xecon\n",
    "    lambda2fit = 741.4 * 0.1/xecon\n",
    "    T = constants[\"Aconst\"]*np.exp(-Distance/lambda1fit)+(1-constants[\"Aconst\"])*np.exp(-Distance/lambda2fit)\n",
    "    A = 1-T\n",
    "\n",
    "    NS = constants[\"sfrac\"]*Ntot\n",
    "    NT = (1-constants[\"sfrac\"])*Ntot\n",
    "    CS= A/constants[\"tauS\"] + kx\n",
    "    CT = A/constants[\"tauT\"] + kx\n",
    "\n",
    "    lambdaM = 1/constants[\"tauM\"] + kxM + constants[\"kqM\"]+ kI\n",
    "    lambdaS = 1/constants[\"tauS\"] + kx + constants[\"kqS\"] + kI\n",
    "    lambdaT = 1/constants[\"tauT\"] + kx + constants[\"kqT\"] + kI\n",
    "    lambdaX = 1/constants[\"tauX\"] + constants[\"kqX\"] + kI\n",
    "    \n",
    "    L1 = (NS * (1-A) / constants[\"tauS\"]) * (1/lambdaS) \n",
    "    L2 = (NT*(1-A)/constants[\"tauT\"])* (1/lambdaT)\n",
    "    L3 = 1/constants[\"tauM\"]*(NS*CS/(lambdaS-lambdaM)*(1/lambdaM-1/lambdaS)+NT*CT/(lambdaT-lambdaM)*(1/lambdaM-1/lambdaT))\n",
    "    L4 = 1/constants[\"tauX\"]*( (NS*CS*kx)/(lambdaS-lambdaM)*(1/(lambdaX-lambdaM)*(1/lambdaM-1/lambdaX)-1/(lambdaX-lambdaS)*(1/lambdaS-1/lambdaX))\n",
    "                  +(NT*CT*kx)/(lambdaT-lambdaM)*(1/(lambdaX-lambdaM)*(1/lambdaM-1/lambdaX)-1/(lambdaX-lambdaT)*(1/lambdaT-1/lambdaX)) )\n",
    "    \n",
    "    if Type == \"S\":\n",
    "        Lxe = L1  \n",
    "    if Type == \"T\":\n",
    "        Lxe = L2    \n",
    "    if Type == \"M\":\n",
    "        Lxe = L3 \n",
    "    if  Type == \"X\":\n",
    "        Lxe = L4\n",
    "    if Type == \"All\":\n",
    "        Lxe = L1+L2+L3+L4\n",
    "        \n",
    "    return Lxe\n",
    "\n",
    "#Light yield dependent on xenon concentration and xenon quenching strength kx: photon arrival time spectra integrated from 0-infinity\n",
    "def Lxekx(xecon,Type,Distance,Ntot,kI,kx):\n",
    "    kxM = kx\n",
    "    if xecon == 0:\n",
    "        A=0\n",
    "    else:\n",
    "        lambda1fit = 12.69 * 0.1/xecon\n",
    "        lambda2fit = 741.4 * 0.1/xecon\n",
    "        T = constants[\"Aconst\"]*np.exp(-Distance/lambda1fit)+(1-constants[\"Aconst\"])*np.exp(-Distance/lambda2fit)\n",
    "        A = 1-T\n",
    "\n",
    "    NS = constants[\"sfrac\"]*Ntot\n",
    "    NT = (1-constants[\"sfrac\"])*Ntot\n",
    "    CS= A/constants[\"tauS\"] + kx\n",
    "    CT = A/constants[\"tauT\"] + kx\n",
    "\n",
    "    lambdaM = 1/constants[\"tauM\"] + kxM + constants[\"kqM\"]+ kI\n",
    "    lambdaS = 1/constants[\"tauS\"] + kx + constants[\"kqS\"] + kI\n",
    "    lambdaT = 1/constants[\"tauT\"] + kx + constants[\"kqT\"] + kI\n",
    "    lambdaX = 1/constants[\"tauX\"] + constants[\"kqX\"] + kI\n",
    "    \n",
    "    L1 = (NS * (1-A) / constants[\"tauS\"]) * (1/lambdaS) \n",
    "    L2 = (NT*(1-A)/constants[\"tauT\"])* (1/lambdaT)\n",
    "    L3 = 1/constants[\"tauM\"]*(NS*CS/(lambdaS-lambdaM)*(1/lambdaM-1/lambdaS)+NT*CT/(lambdaT-lambdaM)*(1/lambdaM-1/lambdaT))\n",
    "    L4 = 1/constants[\"tauX\"]*( (NS*CS*kx)/(lambdaS-lambdaM)*(1/(lambdaX-lambdaM)*(1/lambdaM-1/lambdaX)-1/(lambdaX-lambdaS)*(1/lambdaS-1/lambdaX))\n",
    "                  +(NT*CT*kx)/(lambdaT-lambdaM)*(1/(lambdaX-lambdaM)*(1/lambdaM-1/lambdaX)-1/(lambdaX-lambdaT)*(1/lambdaT-1/lambdaX)) )\n",
    "    \n",
    "    if Type == \"S\":\n",
    "        Lxekx = L1  \n",
    "    if Type == \"T\":\n",
    "        Lxekx = L2    \n",
    "    if Type == \"M\":\n",
    "        Lxekx = L3 \n",
    "    if  Type == \"X\":\n",
    "        Lxekx = L4\n",
    "    if Type == \"All\":\n",
    "        Lxekx = L1+L2+L3+L4\n",
    "        \n",
    "    return Lxekx\n",
    "\n",
    "#Functions needed to perform fits to data\n",
    "\n",
    "#photon arrival time spectra with padding for t<0 (account for the finite time resolution of the detector)\n",
    "def lpad(t,A,kx,kxM,Ntot,kI):\n",
    "    lpad = np.where(t < 0, 0, l(t,A,kx,kxM,'All',Ntot,kI))\n",
    "    return lpad\n",
    "\n",
    "#how the fit would look like without the convolution with a gaussian\n",
    "def fitohnegauss(t,A,kx,kxM,Ntot,kI,c):\n",
    "    fitohnegauss = np.where(t < 0, 0, l(t,A,kx,kxM,'All',Ntot,kI))+c\n",
    "    return fitohnegauss\n",
    "\n",
    "#Convolution----------------------------------------------------------------------------------------\n",
    "def gaussian(x, mu, sigma):\n",
    "    gauss = (1/(sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma)**2)\n",
    "    gaussnorm = gauss / np.sum(gauss)\n",
    "    return gaussnorm\n",
    "\n",
    "def ConvFit(x,xgauss,mu,sigma,A,kx,kxM,Ntot,kI,c):\n",
    "    model=lpad(x, A, kx, kxM, Ntot, kI) + c\n",
    "    gauss=gaussian(xgauss, mu, sigma)\n",
    "    conv = np.convolve(gauss,model, mode='valid')\n",
    "    return conv\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "\n",
    "#check if it is an even number\n",
    "def ist_gerade(zahl):\n",
    "    return zahl % 2 == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bd65715",
   "metadata": {},
   "outputs": [],
   "source": [
    "xecon_mass = np.array([0,3,10,50,100,300]) #xenon concentration in ppm(mass)\n",
    "xecon_mol = np.array([0,3,10,50,100,300]) / 3.3 #xenon concentration in ppm(mol)\n",
    "xeconcont = np.arange(0.0,300.01,0.01)    #xenon concentration in ppm(mass) continous\n",
    "xeconpey = np.arange(0.01,300.01,0.01)    #xenon concentration in ppm(mass) continous for photoelectron yield\n",
    "xeconcont_mol = np.arange(0.0,300.01,0.01) / 3.3    #xenon concentration in ppm(mol) continous\n",
    "xeconly_mol = np.arange(0.01,300.01,0.01) / 3.3    #xenon concentration in ppm(mol) continous for rel. light yield yield\n",
    "xeconpey_mol = np.arange(0.01,300.01,0.01) / 3.3    #xenon concentration in ppm(mol) continous for photoelectron yield\n",
    "xecon_mass_log = np.array([0.01,3,10,50,100,300])\n",
    "xecon_mol_log = np.array([0.01,3,10,50,100,300]) / 3.3\n",
    "\n",
    "Data = np.array([33.63,31.10,39.15,54.51,59.33,64.99]) #see Master's Thesis of C. Vogl; DOI: 10.13140/RG.2.2.23118.54084\n",
    "Data_error = np.array([0.05, 0.03, 0.03,0.05,0.06,0.04])\n",
    "Data_norm = Data/Data[5]\n",
    "Data_norm_error = Data_error/Data[5]\n",
    "path = ['000ppm','003ppm','010ppm','050ppm','100ppm','300ppm']\n",
    "\n",
    "#Colorblind-friendly palette\n",
    "darkblue = '#4477AA'\n",
    "purple = '#AA3377'\n",
    "cyan = '#66CCEE'\n",
    "green = '#228833'\n",
    "yellow = '#CCBB44'\n",
    "grey =  '#BBBBBB'\n",
    "pink = '#EE6677'\n",
    "Color = ['k',darkblue,cyan,green,yellow,pink,purple,grey] #colorblind-friendly palette\n",
    "Colortype = np.array([pink,darkblue,green,yellow,'k'])\n",
    "\n",
    "#Labels\n",
    "Conname = np.array([r\"0.00 $\\mathrm{\\mu mol/mol}$\",r\"0.91 $\\mathrm{\\mu mol/mol}$\",r\"3.03 $\\mathrm{\\mu mol/mol}$\",r\"15.15 $\\mathrm{\\mu mol/mol}$\",r\"30.30 $\\mathrm{\\mu mol/mol}$\",r\"90.91 $\\mathrm{\\mu mol/mol}$\"])\n",
    "Xe_mol_label = r\"Xe concentration [$\\mathrm{\\mu mol/mol}$]\"\n",
    "Xe_g_label = r\"Xe concentration [$\\mathrm{\\mu g/g}$]\"\n",
    "pe_label = \"rel. photoelectron yield [pe]\"\n",
    "tau3_label = \"effective triplet lifetime [ns]\"\n",
    "time_label = \"time [ns]\"\n",
    "relly_label = \"rel. light yield\"\n",
    "countlabel = \"counts (a.u.)\"\n",
    "Type =['S','T','X','M','All']\n",
    "Typename = ['Singlets','Triplets','Xenon','Mixed states','All contributions']\n",
    "\n",
    "x = [0.93,15.,40.,75.] #distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95c40328",
   "metadata": {},
   "outputs": [],
   "source": [
    "constants = {\n",
    "    \"sfrac\": 0.14, #singlet fraction\n",
    "    \"PDE128\": 0.143, #PDE CORRECTION for a 128nm photon\n",
    "    \"PDE150\": 0.235, #PDE CORRECTION for a 150nm photon\n",
    "    \"PDE175\": 0.238, #PDE CORRECTION for a 175nm photon\n",
    "    \"tauS\": 7, #argon excimer singlet lifetime\n",
    "    \"tauT\": 1600, #argon excimer triplet lifetime\n",
    "    \"tauM\": 4700, #mixed state (ArXe)* lifetime\n",
    "    \"tauX\": 20, #xenon excimer lifetime\n",
    "    \"kq\": 1.3 * 1e-4, #self-quenching rate\n",
    "    \"kqS\": 1.3 * 1e-4, \n",
    "    \"kqT\": 1.3 * 1e-4,\n",
    "    \"kqM\": 1.3 * 1e-4,\n",
    "    \"kqX\": 1.3 * 1e-4,\n",
    "    \"Aconst\": 0.62, \n",
    "    \"kI_average\": 3.08 * 1e-4, #average of the calculated bounds for the impurity quenching rate\n",
    "    \"kI_lower_bound\": 2.93 * 1e-4, \n",
    "    \"kI_upper_bound\": 3.73 * 1e-4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38cf3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Photon arrival time spectra - t: 0-10000 - Distance\n",
    "print('--------------------------------------------------------')\n",
    "print('Photon arrival time spectra - t: 0-10000 - Distance')\n",
    "print('--------------------------------------------------------')\n",
    "tmax = 10000\n",
    "t = np.array(range(0, tmax))\n",
    "kx = 2.9 * 1e-4 * xecon_mol #xenon quenching rate\n",
    "kxM = kx \n",
    "Ntot = 1\n",
    "\n",
    "for i in range(len(x)):\n",
    "    Distance = x[i]\n",
    "    print(Distance)\n",
    "    \n",
    "    strDistance = str(x[i])\n",
    "    fig, (ax1,ax2) = plt.subplots(1,2,figsize=(7, 3))\n",
    "    for j in range(0,len(xecon_mol)):\n",
    "        if j == 0:\n",
    "            A = 0 #Absorption of scintillation light\n",
    "        else:\n",
    "            lambda1fit = 12.69 * 0.1/xecon_mol[j]\n",
    "            lambda2fit = 741.4 * 0.1/xecon_mol[j]\n",
    "            T = constants[\"Aconst\"]*np.exp(-Distance/lambda1fit)+(1-constants[\"Aconst\"])*np.exp(-Distance/lambda2fit)\n",
    "            A = 1-T #Absorption of scintillation light\n",
    "        y = l(t,A,kx[j],kxM[j],'All',Ntot,constants[\"kI_average\"])\n",
    "        ax1.plot(t, y, Color[j+1], label = Conname[j])\n",
    "        ax2.plot(t, y, Color[j+1], label = Conname[j])\n",
    "    ax1.set_ylim(1e-5,1e-1)\n",
    "    #plt.xlim(-50,3000)\n",
    "    ax2.set_ylim(1e-5,1e-1)\n",
    "    ax2.set_xlim(-50,9e2)\n",
    "    legend1 = ax1.legend(fontsize=9)\n",
    "    legend1.set_title(strDistance + \" cm\", prop = FontProperties(size=10))\n",
    "    TwoPlots(time_label,countlabel,\"no\",\"log\",1,\"no\",\"no\",time_label,countlabel,\"no\",\"log\",1,\"no\",\"no\",\"Leibelt_Photonarr_zoom\"+ strDistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bf3dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Photon Arrival Time spectra showing the contributions \n",
    "tmax = 10000\n",
    "t = np.array(range(0, tmax))\n",
    "\n",
    "Distance = 15.\n",
    "Ntot = 1\n",
    "xecon_contributions = np.array([0,3,50])/3.3\n",
    "\n",
    "for i in range(1,len(xecon_contributions)):\n",
    "    if i == len(xecon_contributions)-1:\n",
    "        break\n",
    "    if i == 0:\n",
    "        A1 = 0\n",
    "        kx1 = 0\n",
    "        kxM1 = 0\n",
    "        lambda1fit2 = 12.69 * 0.1/xecon_contributions[i+1]\n",
    "        lambda2fit2 = 741.4 * 0.1/xecon_contributions[i+1]\n",
    "        kx2 = 2.9 * 1e-4 * xecon_contributions[i+1]\n",
    "        kxM2 = kx2\n",
    "        T2 = constants[\"Aconst\"]*np.exp(-Distance/lambda1fit2)+(1-constants[\"Aconst\"])*np.exp(-Distance/lambda2fit2)\n",
    "        A2 = 1-T2\n",
    "    else:\n",
    "        lambda1fit1 = 12.69 * 0.1/xecon_contributions[i]\n",
    "        lambda2fit1 = 741.4 * 0.1/xecon_contributions[i]\n",
    "        kx1 = 2.9 * 1e-4 * xecon_contributions[i]\n",
    "        kxM1 = kx1\n",
    "        T1 = constants[\"Aconst\"]*np.exp(-Distance/lambda1fit1)+(1-constants[\"Aconst\"])*np.exp(-Distance/lambda2fit1)\n",
    "        A1 = 1-T1\n",
    "        lambda1fit2 = 12.69 * 0.1/xecon_contributions[i+1]\n",
    "        lambda2fit2 = 741.4 * 0.1/xecon_contributions[i+1]\n",
    "        kx2 = 2.9 * 1e-4 * xecon_contributions[i+1]\n",
    "        kxM2 = kx2\n",
    "        T2 = constants[\"Aconst\"]*np.exp(-Distance/lambda1fit2)+(1-constants[\"Aconst\"])*np.exp(-Distance/lambda2fit2)\n",
    "        A2 = 1-T2\n",
    "\n",
    "    fig, (ax1,ax2) = plt.subplots(1,2,figsize=(7, 3))\n",
    "    for  j in range(0,len(Type)):\n",
    "        if j == 4:\n",
    "            y1 = l(t,A1,kx1,kxM1,Type[j],Ntot,constants[\"kI_average\"])\n",
    "            y2 = l(t,A2,kx2,kxM2,Type[j],Ntot,constants[\"kI_average\"])\n",
    "            ax1.plot(t, y1,\"k--\", label = Typename[j])\n",
    "            ax2.plot(t, y2,\"k--\", label = Typename[j])\n",
    "        else:\n",
    "            y1 = l(t,A1,kx1,kxM1,Type[j],Ntot,constants[\"kI_average\"])\n",
    "            y2 = l(t,A2,kx2,kxM2,Type[j],Ntot,constants[\"kI_average\"])\n",
    "            ax1.plot(t, y1, Colortype[j], label = Typename[j])\n",
    "            ax2.plot(t, y2, Colortype[j], label = Typename[j])\n",
    "    ax1.set_ylim(1e-6,3e-2)\n",
    "    ax2.set_ylim(1e-6,3e-2)\n",
    "    legend1 = ax1.legend(fontsize=9)\n",
    "    legend1.set_title(Conname[1], prop = FontProperties(size=10))\n",
    "    legend2 = ax2.legend(fontsize = 9)\n",
    "    legend2.set_title(Conname[3], prop = FontProperties(size=10))\n",
    "    TwoPlots(time_label,countlabel,\"no\",\"log\",1,\"no\",\"no\",time_label,countlabel,\"no\",\"log\",1,\"no\",\"no\",\"Leibelt_Photonarr_contributions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b85baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative light yield - t: 0-unendlich\n",
    "Distance = 0.93\n",
    "Ntot=1\n",
    "kx = 2.9 * 1e-4 * xeconly_mol\n",
    "fig, ax1 = plt.subplots(figsize=(4, 3))\n",
    "L = Lxe(xeconly_mol,\"All\",Distance,Ntot,constants[\"kI_average\"],kx)\n",
    "norm_val = L[29999]\n",
    "L_norm = norm_val * L\n",
    "ax1.plot(xeconpey_mol, L_norm,color=Color[0], label = \"New model\")\n",
    "#ax1.set_ylim(0.8,1.55)\n",
    "OnePlot(Xe_mol_label,relly_label,\"no\",\"no\",2,Xe_g_label,\"no\",'Leibelt_relly')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ffaba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relative Light Yield showing the contributions\n",
    "Distance = 0.93\n",
    "fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(7, 3))\n",
    "kx = 2.9 * 1e-4 * xeconly_mol\n",
    "LAll = Lxe(xeconly_mol,\"All\",Distance,Ntot,constants[\"kI_average\"],kx)\n",
    "norm_val = 1/LAll[29999]\n",
    "for i in range(0,len(Type)):\n",
    "    y = Lxe(xeconly_mol,Type[i],Distance,Ntot,constants[\"kI_average\"],kx) * norm_val\n",
    "    ax1.plot(xeconly_mol, y, Colortype[i], label = Typename[i])\n",
    "    ax2.plot(xeconly_mol, y, Colortype[i], label = Typename[i])\n",
    "#OnePlot(Xe_mol_label,relly_label,\"log\",\"no\",2,Xe_g_label,\"log\",\"Fields_relly_Types\")\n",
    "legend1 = ax1.legend(fontsize=9)\n",
    "TwoPlots(Xe_mol_label,relly_label,\"no\",\"no\",2,Xe_g_label,\"no\",Xe_mol_label,relly_label,\"log\",\"no\",2,Xe_g_label,\"log\",\"Leibelt_relly_Types_norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ea98e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Photoelectron Yield (pey)\n",
    "Distance = 0.93\n",
    "Ntot = 1\n",
    "kx = 2.9 * 1e-4 * xeconpey_mol\n",
    "\n",
    "for j in range(0,len(Type)-1):\n",
    "    if Type[j] == 'S':\n",
    "        yAllS = Lxe(xeconpey_mol,Type[j],Distance,Ntot,constants[\"kI_average\"],kx)*constants[\"PDE128\"]\n",
    "    elif Type[j] == 'T':\n",
    "        yAllT = Lxe(xeconpey_mol,Type[j],Distance,Ntot,constants[\"kI_average\"],kx)*constants[\"PDE128\"]\n",
    "    elif Type[j] == 'M':\n",
    "        yAllM = Lxe(xeconpey_mol,Type[j],Distance,Ntot,constants[\"kI_average\"],kx)*constants[\"PDE150\"]\n",
    "    elif Type[j] == 'X':\n",
    "        yAllX = Lxe(xeconpey_mol,Type[j],Distance,Ntot,constants[\"kI_average\"],kx)*constants[\"PDE175\"]\n",
    "    else:\n",
    "        PDE = -2000\n",
    "\n",
    "yAll = yAllS + yAllT + yAllM + yAllX\n",
    "norm_val = 1/yAll[29999]\n",
    "\n",
    "#pey\n",
    "fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(7, 3))\n",
    "ax1.plot(xeconpey_mol, yAllS*norm_val, Colortype[0], label = Typename[0])\n",
    "ax1.plot(xeconpey_mol, yAllT*norm_val, Colortype[1], label = Typename[1])\n",
    "ax1.plot(xeconpey_mol, yAllX*norm_val, Colortype[2], label = Typename[2])\n",
    "ax1.plot(xeconpey_mol, yAllM*norm_val, Colortype[3], label = Typename[3])\n",
    "ax1.plot(xeconpey_mol, yAll*norm_val, Colortype[4], label = Typename[4])\n",
    "\n",
    "ax2.plot(xeconpey_mol, yAllS*norm_val, Colortype[0], label = Typename[0])\n",
    "ax2.plot(xeconpey_mol, yAllT*norm_val, Colortype[1], label = Typename[1])\n",
    "ax2.plot(xeconpey_mol, yAllX*norm_val, Colortype[2], label = Typename[2])\n",
    "ax2.plot(xeconpey_mol, yAllM*norm_val, Colortype[3], label = Typename[3])\n",
    "ax2.plot(xeconpey_mol, yAll*norm_val, Colortype[4], label = Typename[4])\n",
    "\n",
    "legend1 = ax1.legend(fontsize=9)\n",
    "TwoPlots(Xe_mol_label,pe_label,\"no\",\"no\",2,Xe_g_label,\"no\",Xe_mol_label,pe_label,\"log\",\"no\",2,Xe_g_label,\"log\",\"Leibelt_pey\")\n",
    "\n",
    "#pey without data\n",
    "fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(7, 3))\n",
    "ax1.plot(xeconpey_mol, yAll*norm_val, 'k', label = 'New model')\n",
    "ax2.plot(xeconpey_mol, yAll*norm_val, 'k', label = 'New model')\n",
    "legend1 = ax1.legend(fontsize=9)\n",
    "TwoPlots(Xe_mol_label,pe_label,\"no\",\"no\",2,Xe_g_label,\"no\",Xe_mol_label,pe_label,\"log\",\"no\",2,Xe_g_label,\"log\",\"Leibelt_pey_withoutData\")\n",
    "\n",
    "#pey compared to data\n",
    "fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(7, 3))\n",
    "ax1.plot(xeconpey_mol, yAll*norm_val, 'k', label = 'New model')\n",
    "ax1.errorbar(xecon_mol, Data_norm, Data_norm_error,fmt = '.',color = Color[6], label = 'LLAMA data')\n",
    "ax2.plot(xeconpey_mol, yAll*norm_val, 'k', label = 'New model')\n",
    "ax2.errorbar(xecon_mol_log, Data_norm, Data_norm_error,fmt = '.',color = Color[6], label = 'LLAMA data')\n",
    "legend1 = ax1.legend(fontsize=9)\n",
    "TwoPlots(Xe_mol_label,pe_label,\"no\",\"no\",2,Xe_g_label,\"no\",Xe_mol_label,pe_label,\"log\",\"no\",2,Xe_g_label,\"log\",\"Leibelt_pey_Data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427c52ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit to the data with fit parameters: kI - sigma,Ntot,c - with weighted bins and rebinned\n",
    "Distance = 15.\n",
    "\n",
    "kIarr= []\n",
    "kIcalcarr = []\n",
    "kxtheoarr = []\n",
    "\n",
    "for i in range(0,len(path)):\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('i:',i,',',path[i])\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "    #set parameters\n",
    "    if i == 0:\n",
    "        kx, kxM, A = 0, 0, 0\n",
    "    else:\n",
    "        kx = 2.9 * 1e-4 * xecon_mol[i]\n",
    "        kxM = 2.9 * 1e-4 * xecon_mol[i]\n",
    "        lambda1fit = 12.69 * 0.1/xecon_mol[i]\n",
    "        lambda2fit = 741.4 * 0.1/xecon_mol[i]\n",
    "        T = constants[\"Aconst\"]*np.exp(-Distance/lambda1fit)+(1-constants[\"Aconst\"])*np.exp(-Distance/lambda2fit)\n",
    "        A = 1-T\n",
    "\n",
    "    # Open the ROOT file and extract the histogram\n",
    "    file = uproot.open(\"C:/Users/maria/Documents/Uni/Bachelorarbeit/Coden/out_stable/stable_\" + path[i]+\"/out.root\")\n",
    "    hist = file[\"hf2_4_1\"]\n",
    "\n",
    "    #  Get the bin contents and edges\n",
    "    counts, bin_edges = hist.to_numpy()\n",
    "\n",
    "    # Rebin\n",
    "    rebin_factor = 2\n",
    "    new_counts = np.add.reduceat(counts, np.arange(0, len(counts), rebin_factor))\n",
    "    new_bin_edges = bin_edges[::rebin_factor]\n",
    "    bin_centers = (new_bin_edges[:-1] + new_bin_edges[1:]) / 2\n",
    "\n",
    "    # Generate bin centers with the specified step size\n",
    "    step_size = new_bin_edges[1]-new_bin_edges[0]\n",
    "    #print('stepsize: ',step_size)\n",
    "\n",
    "    # Gauss x values\n",
    "    xgauss = np.arange(-100, 110, step_size)\n",
    "    #print('xgauss: ',xgauss)\n",
    "\n",
    "    #x-values for the Fit and the data\n",
    "    x_min, x_max = -200, 1e4\n",
    "    x_pad_start, x_conv_max = -200,1e4\n",
    "    #mu, sigma, Ntot, kI, c\n",
    "    bounds = (\n",
    "        [-100, 10, -np.inf, 0., 0],  # Lower bounds\n",
    "        [100, 100, np.inf, 1e-2, np.inf]  # Upper bounds\n",
    "    )\n",
    "    boundscalc = (\n",
    "        [-100, 10, -np.inf, constants[\"kI_lower_bound\"], 0],  # Lower bounds\n",
    "        [100, 100, np.inf, constants[\"kI_upper_bound\"], np.inf]  # Upper bounds\n",
    "    )\n",
    "    if i == 0:\n",
    "        xfit_min, xfit_max = -250, 10000\n",
    "        initial_guesses = [1, 50, 4e6, 3e-4, 15]\n",
    "    elif i == 1:\n",
    "        xfit_min, xfit_max = -250, 10000\n",
    "        initial_guesses = [1, 50, 4e6, 3e-4, 10]\n",
    "    elif i == 2:\n",
    "        xfit_min, xfit_max = -250, 5200\n",
    "        initial_guesses = [1, 50, 4e6, 3e-4, 25]\n",
    "    elif i == 3:\n",
    "        xfit_min, xfit_max = -250, 2100\n",
    "        initial_guesses = [1, 50, 4e6, 3e-4, 25]\n",
    "        bounds = (\n",
    "            [-100, 30, -np.inf, 0., 0],  # Lower bounds\n",
    "            [100, 50, np.inf, 1e-2, np.inf]  # Upper bounds\n",
    "        )\n",
    "        boundscalc = (\n",
    "            [-100, 30, -np.inf, constants[\"kI_lower_bound\"], 0],  # Lower bounds\n",
    "            [100, 50, np.inf, constants[\"kI_upper_bound\"], np.inf]  # Upper bounds\n",
    "        )\n",
    "    elif i == 4:\n",
    "        xfit_min, xfit_max = -250, 2250\n",
    "        initial_guesses = [1, 50, 4e6, 3e-4, 20]\n",
    "        bounds = (\n",
    "            [-np.inf, 30, -np.inf, 0., 0],  # Lower bounds\n",
    "            [np.inf, 50, np.inf, 1e-2, np.inf]  # Upper bounds\n",
    "        )\n",
    "        boundscalc = (\n",
    "            [-np.inf, 30, -np.inf, constants[\"kI_lower_bound\"], 0],  # Lower bounds\n",
    "            [np.inf, 50, np.inf, constants[\"kI_upper_bound\"], np.inf]  # Upper bounds\n",
    "        )\n",
    "    elif i == 5:\n",
    "        xfit_min, xfit_max = -250, 1500\n",
    "        initial_guesses = [1, 50, 4e6, 3e-4, 70]\n",
    "        bounds = (\n",
    "            [-100, -np.inf, -np.inf, 0., 0],  # Lower bounds\n",
    "            [100, np.inf, np.inf, 1e-2, np.inf]  # Upper bounds\n",
    "        )\n",
    "        boundscalc = (\n",
    "            [-100, -np.inf, -np.inf,constants[\"kI_lower_bound\"], 0],  # Lower bounds\n",
    "            [100, np.inf, np.inf, constants[\"kI_upper_bound\"], np.inf]  # Upper bounds\n",
    "        )\n",
    "\n",
    "    # Apply the mask to filter data for x_min to x_max\n",
    "    mask = (bin_centers >= x_min) & (bin_centers <= x_max)\n",
    "    xdata = bin_centers[mask]\n",
    "    ydata = new_counts[mask]\n",
    "\n",
    "    mask_conv = (bin_centers >= x_pad_start) & (bin_centers <= x_conv_max)\n",
    "    xdata_conv = bin_centers[mask_conv]\n",
    "    ydata_conv = new_counts[mask_conv]\n",
    "\n",
    "    mask_fit = (bin_centers >= xfit_min) & (bin_centers <= xfit_max)\n",
    "    xdata_fit = bin_centers[mask_fit]\n",
    "    ydata_fit = new_counts[mask_fit]\n",
    "      \n",
    "    ydata_fit_chopped = ydata_fit[3:][:-2]\n",
    "\n",
    "    # Weight: sqrt(#binentries)\n",
    "    weight = np.where(ydata_fit_chopped == 0, np.inf, np.sqrt(ydata_fit_chopped))  \n",
    "\n",
    "    # Curve fitting\n",
    "    popt_weighted, pcov_weighted = curve_fit(\n",
    "        lambda t_, mu_fit, sigma_fit, Ntot_fit, kI_fit, c_fit: ConvFit(\n",
    "            t_, xgauss, mu_fit, sigma_fit, A, kx, kxM, Ntot_fit, kI_fit, c_fit),\n",
    "        xdata_fit, ydata_fit_chopped, p0=initial_guesses, bounds=bounds, sigma=weight, absolute_sigma=True\n",
    "    )\n",
    "    poptcalc_weighted, pcovcalc_weighted = curve_fit(\n",
    "        lambda t_, mucalc_fit, sigmacalc_fit, Ntotcalc_fit, kIcalc_fit, ccalc_fit: ConvFit(\n",
    "            t_, xgauss, mucalc_fit, sigmacalc_fit, A, kx, kxM, Ntotcalc_fit, kIcalc_fit, ccalc_fit),\n",
    "        xdata_fit, ydata_fit_chopped, p0=initial_guesses, bounds=boundscalc, sigma=weight, absolute_sigma=True\n",
    "    )\n",
    "\n",
    "    mu_fit, sigma_fit, Ntot_fit, kI_fit, c_fit = popt_weighted\n",
    "    mucalc_fit, sigmacalc_fit, Ntotcalc_fit, kIcalc_fit, ccalc_fit = poptcalc_weighted\n",
    "\n",
    "    param_errors = np.sqrt(np.diag(pcov_weighted))\n",
    "    param_errors_calc = np.sqrt(np.diag(pcovcalc_weighted))\n",
    "    \n",
    "    #print('-------------------------------------------------------------------------------------------')\n",
    "    print('Guesses: ','mu: ',initial_guesses[0],'sigma: ',initial_guesses[1],'k_I: ',initial_guesses[3],'c: ',initial_guesses[4])\n",
    "    print('mu_fit:    ',mu_fit,'        mucalc_fit:    ',mucalc_fit)\n",
    "    print('sigma_fit: ',sigma_fit,'          sigmacalc_fit:  ',sigmacalc_fit)\n",
    "    print('Ntot_fit:  ',Ntot_fit,'        Ntotcalc_fit:   ',Ntotcalc_fit)\n",
    "    print('kI_fit:    ',kI_fit,'     kIcalc_fit:     ',kIcalc_fit)\n",
    "    print('c_fit:     ',c_fit,'         ccalc_fit:      ',ccalc_fit)\n",
    "    print('-------------------------------------------------------------------------------------------')\n",
    "    print('mu,sigma,Ntot,kI,c')\n",
    "    print('kI error: ',param_errors[3])\n",
    "    print('kI_calc error: ',param_errors_calc[3])\n",
    "    print('-------------------------------------------------------------------------------------------')\n",
    "    \n",
    "    conv = ConvFit(xdata_fit,xgauss, mu_fit, sigma_fit,A,kx,kxM,Ntot_fit,kI_fit,c_fit)\n",
    "    conv_calc = ConvFit(xdata_fit,xgauss, mucalc_fit, sigmacalc_fit,A,kx,kxM,Ntotcalc_fit,kIcalc_fit,ccalc_fit)\n",
    "\n",
    "    diff = int((len(xdata_fit) - len(conv)))\n",
    "    lim=int(diff/2)\n",
    "    print(diff)\n",
    "\n",
    "    if ist_gerade(diff):\n",
    "        xconv = xdata_fit[lim:][:-lim]\n",
    "    else:\n",
    "        xconv = xdata_fit[lim+1:][:-lim]\n",
    "\n",
    "    # Create subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7, 3))\n",
    "\n",
    "    # Full range plot on the left\n",
    "    ax1.step(xdata, ydata, color='k', label='LLAMA data')\n",
    "    ax1.step(xconv, conv, color=purple, label='Fit $k_I$ with new model')\n",
    "    ax1.step(xconv, conv_calc, color=cyan, label='Fit $k_{I,bounded}$ with new model')\n",
    "\n",
    "    # Zoomed-in plot on the right\n",
    "    ax2.step(xdata, ydata, color='k', label='LLAMA data')\n",
    "    ax2.step(xconv, conv, color=purple, label='Fit $k_I$ with new model')\n",
    "    ax2.step(xconv, conv_calc, color=cyan, label='Fit $k_{I,bounded}$ with new model')\n",
    "    ax2.set_xlim(-500, 1000)\n",
    "    legend1 = ax1.legend(fontsize = 9)\n",
    "    legend1.set_title(Conname[i], prop = FontProperties(size=10))\n",
    "\n",
    "    if i == 0:\n",
    "        ax1.set_ylim(0.5,3e4)\n",
    "        ax2.set_ylim(0.5,3e4)\n",
    "    if i == 1:\n",
    "        ax1.set_ylim(5,6e4)\n",
    "        ax2.set_ylim(5,6e4)\n",
    "    if i == 2:\n",
    "        ax1.set_ylim(10,5e5)\n",
    "        ax2.set_ylim(10,5e5)\n",
    "    if i == 3:\n",
    "        ax1.set_ylim(3,2e5)\n",
    "        ax2.set_ylim(3,2e5)\n",
    "        \n",
    "        \n",
    "    TwoPlots(time_label,\"counts/40ns\",\"no\",\"log\",1,\"no\",\"no\",time_label,\"counts/40ns\",\"no\",\"log\",1,\"no\",\"no\",\"Leibelt_kIFit_\"+ path[i])\n",
    "\n",
    "    kIarr.append(kI_fit)\n",
    "    kIcalcarr.append(kIcalc_fit)\n",
    "    kxtheoarr.append(kx)\n",
    "\n",
    "kIarr = np.array(kIarr)\n",
    "kIcalcarr = np.array(kIcalcarr)\n",
    "kxtheoarr = np.array(kxtheoarr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa65655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit to the data with fit parameters: kI - sigma,Ntot,c - with weighted bins and rebinned + Fit ohne Gauss\n",
    "Distance = 15.\n",
    "\n",
    "for i in range(0,len(path)):\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('i:',i,',',path[i])\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "    #set parameters\n",
    "    if i == 0:\n",
    "        kx, kxM, A = 0, 0, 0\n",
    "    else:\n",
    "        kx = 2.9 * 1e-4 * xecon_mol[i]\n",
    "        kxM = 2.9 * 1e-4 * xecon_mol[i]\n",
    "        lambda1fit = 12.69 * 0.1/xecon_mol[i]\n",
    "        lambda2fit = 741.4 * 0.1/xecon_mol[i]\n",
    "        T = constants[\"Aconst\"]*np.exp(-Distance/lambda1fit)+(1-constants[\"Aconst\"])*np.exp(-Distance/lambda2fit)\n",
    "        A = 1-T\n",
    "\n",
    "    # Open the ROOT file and extract the histogram\n",
    "    file = uproot.open(\"C:/Users/maria/Documents/Uni/Bachelorarbeit/Coden/out_stable/stable_\" + path[i]+\"/out.root\")\n",
    "    hist = file[\"hf2_4_1\"]\n",
    "\n",
    "    #  Get the bin contents and edges\n",
    "    counts, bin_edges = hist.to_numpy()\n",
    "\n",
    "    # Rebin\n",
    "    rebin_factor = 2\n",
    "    new_counts = np.add.reduceat(counts, np.arange(0, len(counts), rebin_factor))\n",
    "    new_bin_edges = bin_edges[::rebin_factor]\n",
    "    bin_centers = (new_bin_edges[:-1] + new_bin_edges[1:]) / 2\n",
    "\n",
    "    # Generate bin centers with the specified step size\n",
    "    step_size = new_bin_edges[1]-new_bin_edges[0]\n",
    "    #print('stepsize: ',step_size)\n",
    "\n",
    "    # Gauss x values\n",
    "    xgauss = np.arange(-100, 110, step_size)\n",
    "    #print('xgauss: ',xgauss)\n",
    "\n",
    "    #x-values for the Fit and the data\n",
    "    x_min, x_max = -200, 1e4\n",
    "    x_pad_start, x_conv_max = -200,1e4\n",
    "\n",
    "    #mu, sigma, Ntot, kI, c\n",
    "    bounds = (\n",
    "        [-100, 10, -np.inf, 1e-7, 0],  # Lower bounds\n",
    "        [100, 100, np.inf, 1e-2, np.inf]  # Upper bounds\n",
    "    )\n",
    "    # boundscalc = (\n",
    "    #     [-100, 10, -np.inf, constants[\"kI_lower_bound\"], 0],  # Lower bounds\n",
    "    #     [100, 100, np.inf, constants[\"kI_upper_bound\"], np.inf]  # Upper bounds\n",
    "    # )\n",
    "    #Ntot,kI, c\n",
    "    bounds_ohnegauss = (\n",
    "        [-np.inf, 0., 0],\n",
    "        [np.inf, 1e-2, np.inf]\n",
    "    )\n",
    "    initial_guesses_ohnegauss = [4e6, 3e-4, 20]\n",
    "\n",
    "    if i == 0:\n",
    "        xfit_min, xfit_max = -250, 10000\n",
    "        initial_guesses = [1, 50, 4e6, 3e-4, 15]\n",
    "    elif i == 1:\n",
    "        xfit_min, xfit_max = -250, 10000\n",
    "        initial_guesses = [1, 50, 4e6, 3e-4, 10]\n",
    "    elif i == 2:\n",
    "        xfit_min, xfit_max = -250, 5200\n",
    "        initial_guesses = [1, 50, 4e6, 3e-4, 25]\n",
    "    elif i == 3:\n",
    "        xfit_min, xfit_max = -250, 2100\n",
    "        initial_guesses = [1, 50, 4e6, 3e-4, 25]\n",
    "        bounds = (\n",
    "            [-100, 30, -np.inf, 1e-7, 0],  # Lower bounds\n",
    "            [100, 50, np.inf, 1e-2, np.inf]  # Upper bounds\n",
    "        )\n",
    "        # boundscalc = (\n",
    "        #     [-100, 30, -np.inf, constants[\"kI_lower_bound\"], 0],  # Lower bounds\n",
    "        #     [100, 50, np.inf, constants[\"kI_upper_bound\"], np.inf]  # Upper bounds\n",
    "        # )\n",
    "    elif i == 4:\n",
    "        xfit_min, xfit_max = -250, 2250\n",
    "        initial_guesses = [1, 50, 4e6, 3e-4, 20]\n",
    "        bounds = (\n",
    "            [-np.inf, 30, -np.inf, 1e-7, 0],  # Lower bounds\n",
    "            [np.inf, 50, np.inf, 1e-2, np.inf]  # Upper bounds\n",
    "        )\n",
    "        # boundscalc = (\n",
    "        #     [-np.inf, 30, -np.inf, constants[\"kI_lower_bound\"], 0],  # Lower bounds\n",
    "        #     [np.inf, 50, np.inf, constants[\"kI_upper_bound\"], np.inf]  # Upper bounds\n",
    "        # )\n",
    "    elif i == 5:\n",
    "        xfit_min, xfit_max = -250, 1500\n",
    "        initial_guesses = [1, 50, 4e6, 3e-4, 70]\n",
    "        bounds = (\n",
    "            [-100, -np.inf, -np.inf, 1e-7, 0],  # Lower bounds\n",
    "            [100, np.inf, np.inf, 1e-2, np.inf]  # Upper bounds\n",
    "        )\n",
    "        # boundscalc = (\n",
    "        #     [-100, -np.inf, -np.inf,constants[\"kI_lower_bound\"], 0],  # Lower bounds\n",
    "        #     [100, np.inf, np.inf, constants[\"kI_upper_bound\"], np.inf]  # Upper bounds\n",
    "        # )\n",
    "\n",
    "    # Apply the mask to filter data for x_min to x_max\n",
    "    mask = (bin_centers >= x_min) & (bin_centers <= x_max)\n",
    "    xdata = bin_centers[mask]\n",
    "    ydata = new_counts[mask]\n",
    "\n",
    "    mask_conv = (bin_centers >= x_pad_start) & (bin_centers <= x_conv_max)\n",
    "    xdata_conv = bin_centers[mask_conv]\n",
    "    ydata_conv = new_counts[mask_conv]\n",
    "\n",
    "    mask_fit = (bin_centers >= xfit_min) & (bin_centers <= xfit_max)\n",
    "    xdata_fit = bin_centers[mask_fit]\n",
    "    ydata_fit = new_counts[mask_fit]\n",
    "      \n",
    "    ydata_fit_chopped = ydata_fit[3:][:-2]\n",
    "\n",
    "    # Weight: sqrt(#binentries)\n",
    "    weight = np.where(ydata_fit_chopped == 0, np.inf, np.sqrt(ydata_fit_chopped))  \n",
    "    weight_ohnegauss = np.where(ydata_fit == 0, np.inf, np.sqrt(ydata_fit)) \n",
    "\n",
    "    # Curve fitting\n",
    "    popt_weighted, pcov_weighted = curve_fit(\n",
    "        lambda t_, mu_fit, sigma_fit, Ntot_fit, kI_fit, c_fit: ConvFit(\n",
    "            t_, xgauss, mu_fit, sigma_fit, A, kx, kxM, Ntot_fit, kI_fit, c_fit),\n",
    "        xdata_fit, ydata_fit_chopped, p0=initial_guesses, bounds=bounds, sigma=weight, absolute_sigma=True\n",
    "    )\n",
    "    # poptcalc_weighted, pcovcalc_weighted = curve_fit(\n",
    "    #     lambda t_, mucalc_fit, sigmacalc_fit, Ntotcalc_fit, kIcalc_fit, ccalc_fit: ConvFit(\n",
    "    #         t_, xgauss, mucalc_fit, sigmacalc_fit, A, kx, kxM, Ntotcalc_fit, kIcalc_fit, ccalc_fit),\n",
    "    #     xdata_fit, ydata_fit_chopped, p0=initial_guesses, bounds=boundscalc, sigma=weight, absolute_sigma=True\n",
    "    # )\n",
    "    poptohnegauss_weighted, pcovohnegauss_weighted = curve_fit(\n",
    "        lambda t_, Ntotohnegauss_fit, kIohnegauss_fit, cohnegauss_fit: fitohnegauss(\n",
    "            t_, A, kx, kxM, Ntotohnegauss_fit, kIohnegauss_fit, cohnegauss_fit),\n",
    "        xdata_fit, ydata_fit, p0=initial_guesses_ohnegauss, bounds=bounds_ohnegauss, sigma=weight_ohnegauss, absolute_sigma=True\n",
    "    )\n",
    "\n",
    "    mu_fit, sigma_fit, Ntot_fit, kI_fit, c_fit = popt_weighted\n",
    "    # mucalc_fit, sigmacalc_fit, Ntotcalc_fit, kIcalc_fit, ccalc_fit = poptcalc_weighted\n",
    "    Ntotohnegauss_fit, kIohnegauss_fit, cohnegauss_fit = poptohnegauss_weighted\n",
    "\n",
    "    param_errors = np.sqrt(np.diag(pcov_weighted))\n",
    "    # param_errors_calc = np.sqrt(np.diag(pcovcalc_weighted))\n",
    "    param_errors_ohnegauss = np.sqrt(np.diag(pcovohnegauss_weighted))\n",
    "    \n",
    "    # #print('-------------------------------------------------------------------------------------------')\n",
    "    # print('Guesses: ','mu: ',initial_guesses[0],'sigma: ',initial_guesses[1],'k_I: ',initial_guesses[3],'c: ',initial_guesses[4])\n",
    "    # print('mu_fit:    ',mu_fit,'        mucalc_fit:    ',mucalc_fit)\n",
    "    # print('sigma_fit: ',sigma_fit,'          sigmacalc_fit:  ',sigmacalc_fit)\n",
    "    # print('Ntot_fit:  ',Ntot_fit,'        Ntotcalc_fit:   ',Ntotcalc_fit)\n",
    "    # print('kI_fit:    ',kI_fit,'     kIcalc_fit:     ',kIcalc_fit)\n",
    "    # print('c_fit:     ',c_fit,'         ccalc_fit:      ',ccalc_fit)\n",
    "    \n",
    "    conv = ConvFit(xdata_fit,xgauss, mu_fit, sigma_fit,A,kx,kxM,Ntot_fit,kI_fit,c_fit)\n",
    "    # conv_calc = ConvFit(xdata_fit,xgauss, mucalc_fit, sigmacalc_fit,A,kx,kxM,Ntotcalc_fit,kIcalc_fit,ccalc_fit)\n",
    "    ohnegauss = fitohnegauss(xdata_fit,A,kx,kxM,Ntotohnegauss_fit,kIohnegauss_fit,cohnegauss_fit)\n",
    "\n",
    "    diff = int((len(xdata_fit) - len(conv)))\n",
    "    lim=int(diff/2)\n",
    "    print(diff)\n",
    "    \n",
    "    if ist_gerade(diff):\n",
    "        xconv = xdata_fit[lim:][:-lim]\n",
    "    else:\n",
    "        xconv = xdata_fit[lim+1:][:-lim]\n",
    "\n",
    "    # Create subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7, 3))\n",
    "\n",
    "    # Full range plot on the left\n",
    "    ax1.step(xdata, ydata, color='k', label='LLAMA data')\n",
    "    ax1.step(xconv, conv, color=purple, label='Fit $k_I$ with new model')\n",
    "    # ax1.step(xconv, conv_calc, color=cyan, label='Fit $k_{I,calc}$ with new model')\n",
    "    ax1.step(xdata_fit, ohnegauss, color=green, label='Fit $k_I$ without convolution')\n",
    "\n",
    "    # Zoomed-in plot on the right\n",
    "    ax2.step(xdata, ydata, color='k', label='LLAMA data')\n",
    "    ax2.step(xconv, conv, color=purple, label='Fit $k_I$ with new model')\n",
    "    # ax2.step(xconv, conv_calc, color=cyan, label='Fit $k_{I,calc}$ with new model')\n",
    "    ax2.step(xdata_fit, ohnegauss, color=green, label='Fit $k_I$ without convolution')\n",
    "    ax2.set_xlim(-500, 1000)\n",
    "    legend1 = ax1.legend(fontsize = 9)\n",
    "    legend1.set_title(Conname[i], prop = FontProperties(size=10))\n",
    "\n",
    "    if i == 0:\n",
    "        ax1.set_ylim(0.5,1e4)\n",
    "        ax2.set_ylim(0.5,1e4)\n",
    "    if i == 1:\n",
    "        ax1.set_ylim(3,3e4)\n",
    "        ax2.set_ylim(3,3e4)\n",
    "    if i == 2:\n",
    "        ax1.set_ylim(10,7e4)\n",
    "        ax2.set_ylim(10,7e4)\n",
    "        \n",
    "    TwoPlots(time_label,\"counts/40ns\",\"no\",\"log\",1,\"no\",\"no\",time_label,\"counts/40ns\",\"no\",\"log\",1,\"no\",\"no\",\"Leibelt_kIFit_ohnegauss_\"+ path[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137084c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit to the data with fit parameters: kx - sigma,Ntot,c - with weighted bins and rebinned\n",
    "#kI set to 4.28e-4\n",
    "Distance = 15.\n",
    "kIfit = 4.28e-4\n",
    "\n",
    "kxarr = []\n",
    "for i in range(0,len(path)): \n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('i:',i,',',path[i])\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    if i == 0:\n",
    "        A = 0\n",
    "    else:\n",
    "        lambda1fit = 12.69 * 0.1/xecon_mol[i]\n",
    "        lambda2fit = 741.4 * 0.1/xecon_mol[i]\n",
    "        T = constants[\"Aconst\"]*np.exp(-Distance/lambda1fit)+(1-constants[\"Aconst\"])*np.exp(-Distance/lambda2fit)\n",
    "        A = 1-T\n",
    "\n",
    "    # Open the ROOT file and extract the histogram\n",
    "    file = uproot.open(\"C:/Users/maria/Documents/Uni/Bachelorarbeit/Coden/out_stable/stable_\" + path[i]+\"/out.root\")\n",
    "    hist = file[\"hf2_4_1\"]\n",
    "\n",
    "    #  Get the bin contents and edges\n",
    "    counts, bin_edges = hist.to_numpy()\n",
    "\n",
    "    # Rebin\n",
    "    rebin_factor = 2\n",
    "    new_counts = np.add.reduceat(counts, np.arange(0, len(counts), rebin_factor))\n",
    "    new_bin_edges = bin_edges[::rebin_factor]\n",
    "    bin_centers = (new_bin_edges[:-1] + new_bin_edges[1:]) / 2\n",
    "\n",
    "    # Generate bin centers with the specified step size\n",
    "    step_size = new_bin_edges[1]-new_bin_edges[0]\n",
    "    #print('stepsize: ',step_size)\n",
    "\n",
    "    # Gauss x values\n",
    "    xgauss = np.arange(-100, 110, step_size)\n",
    "    #print('xgauss: ',xgauss)\n",
    "\n",
    "    #x-values for the Fit and the data\n",
    "    x_min, x_max = -250, 1e4\n",
    "    x_pad_start, x_conv_max = -250,1e4\n",
    "\n",
    "    #mu, sigma, kx, Ntot, c\n",
    "    bounds = (\n",
    "        [-100,10,0,0,0],  # Lower bounds\n",
    "        [100,100,1,np.inf,np.inf]  # Upper bounds\n",
    "    )\n",
    "    if i == 0:\n",
    "        xfit_min, xfit_max = -250, 10000\n",
    "        initial_guesses = [1, 50, 2.9 * 1e-4 * xecon_mol[0],4e6, 2]\n",
    "    elif i == 1:\n",
    "        xfit_min, xfit_max = -250, 10000\n",
    "        initial_guesses = [1, 50, 2.9 * 1e-4 * xecon_mol[1],4e6, 10]\n",
    "        bounds = (\n",
    "            [-100, 10, 0 ,0, 0],  # Lower bounds\n",
    "            [100, 100, 1e-2 ,np.inf, np.inf]  # Upper bounds\n",
    "        )\n",
    "    elif i == 2:\n",
    "        xfit_min, xfit_max = -250, 5200\n",
    "        initial_guesses = [1, 50, 2.9 * 1e-4 * xecon_mol[2],4e6, 25]\n",
    "    elif i == 3:\n",
    "        xfit_min, xfit_max = -250, 2100\n",
    "        initial_guesses = [1, 50, 2.9 * 1e-4 * xecon_mol[3],4e6, 25]\n",
    "        bounds = (\n",
    "            [-100, 30, 0 ,-np.inf, 0],  # Lower bounds\n",
    "            [100, 50, 1 ,np.inf, np.inf]  # Upper bounds\n",
    "        )\n",
    "    elif i == 4:\n",
    "        xfit_min, xfit_max = -250, 2250\n",
    "        initial_guesses = [1, 50, 2.9 * 1e-4 * xecon_mol[4],4e6, 20]\n",
    "        bounds = (\n",
    "            [-100,30,0,-np.inf,0],  # Lower bounds\n",
    "            [100,50,1,np.inf,np.inf]  # Upper bounds\n",
    "        )\n",
    "    elif i == 5:\n",
    "        xfit_min, xfit_max = -250, 1500\n",
    "        initial_guesses = [1, 50, 2.9 * 1e-4 * xecon_mol[5],4e6, 70]\n",
    "        bounds = (\n",
    "            [-100,30,0,-np.inf,0],  # Lower bounds\n",
    "            [100,50,1,np.inf,np.inf]  # Upper bounds\n",
    "        )\n",
    "    # Apply the mask to filter data for x_min to x_max\n",
    "    mask = (bin_centers >= x_min) & (bin_centers <= x_max)\n",
    "    xdata = bin_centers[mask]\n",
    "    ydata = new_counts[mask]\n",
    "\n",
    "    mask_conv = (bin_centers >= x_pad_start) & (bin_centers <= x_conv_max)\n",
    "    xdata_conv = bin_centers[mask_conv]\n",
    "    ydata_conv = new_counts[mask_conv]\n",
    "\n",
    "    mask_fit = (bin_centers >= xfit_min) & (bin_centers <= xfit_max)\n",
    "    xdata_fit = bin_centers[mask_fit]\n",
    "    ydata_fit = new_counts[mask_fit]\n",
    "      \n",
    "    ydata_fit_chopped = ydata_fit[3:][:-2]\n",
    "\n",
    "    # Weight: sqrt(#binentries)\n",
    "    weight = np.where(ydata_fit_chopped == 0, np.inf, np.sqrt(ydata_fit_chopped))\n",
    "\n",
    "    # Curve fitting\n",
    "    popt_weighted, pcov_weighted = curve_fit(\n",
    "        lambda  t_,mu_fit,sigma_fit,kx_fit,Ntot_fit,c_fit: ConvFit(t_, xgauss, mu_fit, sigma_fit,A,kx_fit,kx_fit,Ntot_fit,kIfit,c_fit), \n",
    "        xdata_fit, \n",
    "        ydata_fit_chopped, \n",
    "        p0=initial_guesses,\n",
    "        bounds=bounds, \n",
    "        sigma=weight, \n",
    "        absolute_sigma=True\n",
    "    )\n",
    "    mu_fit,sigma_fit,kx_fit,Ntot_fit,c_fit = popt_weighted\n",
    "    param_errors = np.sqrt(np.diag(pcov_weighted))\n",
    "    #print('-------------------------------------------------------------------------------------------')\n",
    "    print('Guesses: ','mu: ',initial_guesses[0],'sigma: ',initial_guesses[1],'k_x: ',initial_guesses[2],'c: ',initial_guesses[4])\n",
    "    print('mu_fit:    ',mu_fit)\n",
    "    print('sigma_fit: ',sigma_fit)\n",
    "    print('kx_fit: ',kx_fit)\n",
    "    print('Ntot_fit:  ',Ntot_fit)\n",
    "    print('c_fit:     ',c_fit)\n",
    "\n",
    "    print('kx error: ',param_errors[2])\n",
    "    \n",
    "    conv = ConvFit(xdata_fit,xgauss, mu_fit, sigma_fit,A,kx_fit,kx_fit,Ntot_fit,kIfit,c_fit)\n",
    "\n",
    "    diff = int((len(xdata_fit) - len(conv)))\n",
    "    lim=int(diff/2)\n",
    "\n",
    "    if ist_gerade(diff):\n",
    "        xconv = xdata_fit[lim:][:-lim]\n",
    "    else:\n",
    "        xconv = xdata_fit[lim+1:][:-lim]\n",
    "\n",
    "    # Create subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7,3))\n",
    "    if i == 1:\n",
    "        ax1.set_ylim(1,2e4)\n",
    "        ax2.set_ylim(1,2e4)\n",
    "    if i == 2:\n",
    "        ax1.set_ylim(10,2e4)\n",
    "        ax2.set_ylim(10,2e4)\n",
    "    if i == 3:\n",
    "        ax1.set_ylim(5,5e4)\n",
    "        ax2.set_ylim(5,5e4)\n",
    "    # Full range plot on the left\n",
    "    ax1.step(xdata, ydata, color='k', label='LLAMA data')\n",
    "    ax1.step(xconv, conv, color=cyan, label='Fit of $k_x$ with new model')\n",
    "\n",
    "    # Zoomed-in plot on the right\n",
    "    ax2.step(xdata, ydata, color='k', label='LLAMA data')\n",
    "    ax2.step(xconv, conv, color=cyan, label='conv')\n",
    "    ax2.set_xlim(-500, 1000)\n",
    "    legend1 = ax1.legend(fontsize = 9)\n",
    "    legend1.set_title(Conname[i], prop = FontProperties(size=10))\n",
    "\n",
    "    TwoPlots(time_label,countlabel,\"no\",\"log\",1,\"no\",\"no\",time_label,countlabel,\"no\",\"log\",1,\"no\",\"no\",\"Leibelt_kxFit_\"+ path[i])\n",
    "\n",
    "    kxarr.append(kx_fit)\n",
    "kxarr = np.array(kxarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e4768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kx and kI from fit vs. xecon concentration\n",
    "print('xecon_mol: ',xecon_mol)\n",
    "print('kIarr:     ',kIarr)\n",
    "print('kIcalcarr: ',kIcalcarr)\n",
    "print('kxarr:     ',kxarr)\n",
    "print('kxtheoarr: ',kxtheoarr)\n",
    "\n",
    "xaxis = xecon_mol\n",
    "y1 = kIarr\n",
    "y2 = kIcalcarr\n",
    "ybound1 = np.ones(6, dtype=int)*constants[\"kI_lower_bound\"]\n",
    "ybound2 = np.ones(6, dtype=int)*constants[\"kI_upper_bound\"]\n",
    "y3 = kxarr*3.3\n",
    "y4 = kxtheoarr*3.3\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(4,3))\n",
    "ax1.plot(xaxis, ybound1,\"--\", color = 'k', label=r'$k_I$ bounds')\n",
    "ax1.plot(xaxis, ybound2,\"--\", color = 'k')\n",
    "ax1.plot(xaxis, y1, \".\",color = darkblue, label=r'$k_I$ from fit')\n",
    "ax1.plot(xaxis, y2, \".\", color = green, label=r'$k_{I,bounded}$ from fit')\n",
    "ax1.legend(fontsize = 9)\n",
    "formatter = ticker.ScalarFormatter()\n",
    "formatter.set_powerlimits((-3, 4))  # Werte außerhalb dieses Bereichs werden in wissenschaftlicher Notation angezeigt\n",
    "ax1.yaxis.set_major_formatter(formatter)\n",
    "ax1.set_ylim(-5e-5,7e-4)\n",
    "OnePlot(Xe_mol_label,\"$k_I$ [1/ns]\",\"no\",\"no\",2,Xe_g_label,\"no\",\"Leibelt_kIvsxecon\")\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(4,3))\n",
    "ax1.plot(xaxis, y4, 'k-', label='linear approach')\n",
    "ax1.plot(xaxis, y3, \".\", color = purple, label='$k_x$ from fit')\n",
    "ax1.legend(fontsize = 9)\n",
    "OnePlot(Xe_mol_label,r\"$k_x$ [1/(ns $\\mu$mol/mol)]\",\"no\",\"no\",2,Xe_g_label,\"no\",\"Leibelt_kxvsxecon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd4e91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pey mit kx von fit compared to data\n",
    "Distance = 0.93\n",
    "Ntot = 1\n",
    "\n",
    "kIfit_average = (kIarr[0]+kIarr[1]+kIarr[2])/3\n",
    "print(\"kI_average of reasonable fit values\",kIfit_average)\n",
    "kxfit = kxarr\n",
    "kx = 2.9 * 1e-4 * xeconpey_mol\n",
    "\n",
    "yAllarr_fit  = []\n",
    "for i in range(0,len(kxarr)):\n",
    "    for j in range(0,len(Type)-1):\n",
    "        if Type[j] == 'S':\n",
    "            yAllS_fit = Lxekx(xecon_mol[i],Type[j],Distance,Ntot,kIfit_average,kxfit[i])*constants[\"PDE128\"]\n",
    "            yAllS_fit_norm = Lxekx(300/3.3,Type[j],Distance,Ntot,kIfit_average,kxfit[5])*constants[\"PDE128\"]\n",
    "        elif Type[j] == 'T':\n",
    "            yAllT_fit = Lxekx(xecon_mol[i],Type[j],Distance,Ntot,kIfit_average,kxfit[i])*constants[\"PDE128\"]\n",
    "            yAllT_fit_norm = Lxekx(300/3.3,Type[j],Distance,Ntot,kIfit_average,kxfit[5])*constants[\"PDE128\"]\n",
    "        elif Type[j] == 'M':\n",
    "            yAllM_fit = Lxekx(xecon_mol[i],Type[j],Distance,Ntot,kIfit_average,kxfit[i])*constants[\"PDE150\"]\n",
    "            yAllM_fit_norm = Lxekx(300/3.3,Type[j],Distance,Ntot,kIfit_average,kxfit[5])*constants[\"PDE150\"]\n",
    "        elif Type[j] == 'X':\n",
    "            yAllX_fit = Lxekx(xecon_mol[i],Type[j],Distance,Ntot,kIfit_average,kxfit[i])*constants[\"PDE175\"]\n",
    "            yAllX_fit_norm = Lxekx(300/3.3,Type[j],Distance,Ntot,kIfit_average,kxfit[5])*constants[\"PDE175\"]\n",
    "        else:\n",
    "            PDE = -2000\n",
    "    yAll_fit = yAllS_fit + yAllT_fit + yAllM_fit+ yAllX_fit\n",
    "    yAllarr_fit.append(yAll_fit)\n",
    "yAll_fit_norm = yAllS_fit_norm + yAllT_fit_norm + yAllM_fit_norm + yAllX_fit_norm\n",
    "yAll_fit_norm_val = 1 / yAll_fit_norm\n",
    "\n",
    "for j in range(0,len(Type)-1):\n",
    "    if Type[j] == 'S':\n",
    "        yAllS = Lxe(xeconpey_mol,Type[j],Distance,Ntot,constants[\"kI_average\"],kx)*constants[\"PDE128\"]\n",
    "        yAllS_norm = Lxekx(300/3.3,Type[j],Distance,Ntot,constants[\"kI_average\"],2.9 * 1e-4 * (300/3.3))*constants[\"PDE128\"]\n",
    "    elif Type[j] == 'T':\n",
    "        yAllT = Lxe(xeconpey_mol,Type[j],Distance,Ntot,constants[\"kI_average\"],kx)*constants[\"PDE128\"]\n",
    "        yAllT_norm = Lxekx(300/3.3,Type[j],Distance,Ntot,constants[\"kI_average\"],2.9 * 1e-4 * (300/3.3))*constants[\"PDE128\"]\n",
    "    elif Type[j] == 'M':\n",
    "        yAllM = Lxe(xeconpey_mol,Type[j],Distance,Ntot,constants[\"kI_average\"],kx)*constants[\"PDE150\"]\n",
    "        yAllM_norm = Lxekx(300/3.3,Type[j],Distance,Ntot,constants[\"kI_average\"],2.9 * 1e-4 * (300/3.3))*constants[\"PDE150\"]\n",
    "    elif Type[j] == 'X':\n",
    "        yAllX = Lxe(xeconpey_mol,Type[j],Distance,Ntot,constants[\"kI_average\"],kx)*constants[\"PDE175\"]\n",
    "        yAllX_norm = Lxekx(300/3.3,Type[j],Distance,Ntot,constants[\"kI_average\"],2.9 * 1e-4 * (300/3.3))*constants[\"PDE175\"]\n",
    "    else:\n",
    "        PDE = -2000\n",
    "\n",
    "yAll = yAllS + yAllT + yAllM + yAllX\n",
    "\n",
    "yAll_norm = yAllS_norm+yAllT_norm+yAllM_norm+yAllX_norm\n",
    "norm_val = 1/yAll_norm\n",
    "\n",
    "yAllarr_fit = np.array(yAllarr_fit)\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(7, 3))\n",
    "ax1.plot(xeconpey_mol, yAll*norm_val, 'k', label = 'New model')\n",
    "ax1.errorbar(xecon_mol, Data_norm, Data_norm_error,fmt = '.',color = Color[6], label = 'LLAMA data')\n",
    "ax1.plot(xecon_mol, yAllarr_fit*yAll_fit_norm_val, '.', color = darkblue, label = 'New model with $k_{x,fit}$')\n",
    "\n",
    "ax2.plot(xeconpey_mol, yAll*norm_val, \"k\", label = 'New model')\n",
    "ax2.errorbar(xecon_mol_log, Data_norm, Data_norm_error,fmt = '.',color = Color[6], label = 'LLAMA data')\n",
    "ax2.plot(xecon_mol_log, yAllarr_fit*yAll_fit_norm_val, '.', color = darkblue, label = 'New model with $k_{x,fit}')\n",
    "legend1 = ax1.legend(fontsize=9)\n",
    "TwoPlots(Xe_mol_label,pe_label,\"no\",\"no\",2,Xe_g_label,\"no\",Xe_mol_label,pe_label,\"log\",\"no\",2,Xe_g_label,\"log\",\"Leibelt_pey_Data_kxkIfit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a09eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detector Distance Dependency of the Photon Arrival Time Spectra\n",
    "print('--------------------------------------------------------')\n",
    "print('Photon arrival time spectra - t: 0-10000 - Distance')\n",
    "print('--------------------------------------------------------')\n",
    "xecon_mario = np.array([3,50])/3.3\n",
    "mario_name = np.array([r\"0.91 $\\mu$mol/mol\",r\"15.15 $\\mu$mol/mol\"])\n",
    "tmax = 10000\n",
    "t = np.array(range(0, tmax))\n",
    "kIfit = 4.28e-4\n",
    "kx = [kxarr[1],kxarr[3]]\n",
    "kxM = kx\n",
    "Ntot = 1\n",
    "\n",
    "yAll0 = []\n",
    "yAll1 = []\n",
    "for j in range(1,len(x)):\n",
    "    strDistance = str(x[j])\n",
    "    Distance = x[j]\n",
    "    print(Distance)\n",
    "\n",
    "    lambda1fit0 = 12.69 * 0.1/xecon_mario[0]\n",
    "    lambda2fit0 = 741.4 * 0.1/xecon_mario[0]\n",
    "    T0 = constants[\"Aconst\"]*np.exp(-Distance/lambda1fit0)+(1-constants[\"Aconst\"])*np.exp(-Distance/lambda2fit0)\n",
    "    A0 = 1-T0\n",
    "    lambda1fit1 = 12.69 * 0.1/xecon_mario[1]\n",
    "    lambda2fit1 = 741.4 * 0.1/xecon_mario[1]\n",
    "    T1 = constants[\"Aconst\"]*np.exp(-Distance/lambda1fit1)+(1-constants[\"Aconst\"])*np.exp(-Distance/lambda2fit1)\n",
    "    A1 = 1-T1\n",
    "\n",
    "    y0 = l(t,A0,kx[0],kxM[0],'All',Ntot,kIfit)\n",
    "    y1 = l(t,A1,kx[1],kxM[1],'All',Ntot,kIfit)\n",
    "    yAll0.append(y0)\n",
    "    yAll1.append(y1)\n",
    "\n",
    "yAll0 = np.array(yAll0)\n",
    "yAll1 = np.array(yAll1)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7,3))\n",
    "ax1.plot(t, yAll0[0], 'k', label = str(x[1])+\" cm\")\n",
    "ax2.plot(t, yAll1[0], 'k', label = str(x[1])+\" cm\")\n",
    "ax1.plot(t, yAll0[1], purple, label = str(x[2])+\" cm\")\n",
    "ax2.plot(t, yAll1[1], purple, label = str(x[2])+\" cm\")\n",
    "ax1.plot(t, yAll0[2], yellow, label = str(x[3])+\" cm\")\n",
    "ax2.plot(t, yAll1[2], yellow, label = str(x[3])+\" cm\")\n",
    "ax1.set_xlim(-500,4e3)\n",
    "ax2.set_xlim(-500,4e3)\n",
    "ax1.set_ylim(1e-6,1e-2)\n",
    "ax2.set_ylim(1e-6,1e-2)\n",
    "\n",
    "legend1 = ax1.legend(fontsize=9)\n",
    "legend1.set_title(mario_name[0], prop = FontProperties(size=10))\n",
    "legend2 = ax2.legend(fontsize=9)\n",
    "legend2.set_title(mario_name[1], prop = FontProperties(size=10))\n",
    "TwoPlots(time_label,countlabel,\"no\",\"log\",1,\"no\",\"no\",time_label,countlabel,\"no\",\"log\",1,\"no\",\"no\",\"Leibelt_Photonarr_distance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d54145",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detector Distance Dependency of the Photoelectron Yield\n",
    "Ntot = 1\n",
    "kx = kxarr\n",
    "yAllarr = []\n",
    "kIfit = 4.28e-4\n",
    "\n",
    "for i in range(0,len(x)):\n",
    "    Distance = x[i]\n",
    "    strDistance = str(Distance)    \n",
    "    for j in range(0,len(Type)-1):\n",
    "        if Type[j] == 'S':\n",
    "            yAllS = Lxe(xecon_mol,Type[j],Distance,Ntot,kIfit,kx)*constants[\"PDE128\"]\n",
    "        elif Type[j] == 'T':\n",
    "            yAllT = Lxe(xecon_mol,Type[j],Distance,Ntot,kIfit,kx)*constants[\"PDE128\"]\n",
    "        elif Type[j] == 'M':\n",
    "            yAllM = Lxe(xecon_mol,Type[j],Distance,Ntot,kIfit,kx)*constants[\"PDE150\"]\n",
    "        elif Type[j] == 'X':\n",
    "            yAllX = Lxe(xecon_mol,Type[j],Distance,Ntot,kIfit,kx)*constants[\"PDE175\"]\n",
    "        else:\n",
    "            PDE = -2000\n",
    "\n",
    "    yAll = yAllS + yAllT + yAllM + yAllX\n",
    "    yAllarr.append(yAll)\n",
    "yAllarr = np.array(yAllarr)\n",
    "\n",
    "norm_val = 1/yAllarr[0][5]\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(7, 3))\n",
    "colordistance = [darkblue,\"k\",purple,yellow]\n",
    "for j in range(0,len(yAllarr)):\n",
    "    Distance = x[j]\n",
    "    strDistance = str(Distance)\n",
    "    \n",
    "    print(strDistance)\n",
    "\n",
    "    ax1.plot(xecon_mol, yAllarr[j]*norm_val, \".\",color=colordistance[j], label = strDistance + \" cm\")\n",
    "    ax2.plot(xecon_mol_log, yAllarr[j]*norm_val, \".\",color=colordistance[j], label = strDistance + \" cm\")\n",
    "    legend1 = ax1.legend(fontsize=9)\n",
    "TwoPlots(Xe_mol_label,pe_label,\"no\",\"no\",2,Xe_g_label,\"no\",Xe_mol_label,pe_label,\"log\",\"no\",2,Xe_g_label,\"log\",\"Leibelt_pey_withoutData_distance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394f8d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show that the impurities (kI) cause the dip in the photoelectron yield\n",
    "kI_values = np.linspace(0, 1e-3, 1000)  # 5 values from 0 to 0.01 for demonstration\n",
    "\n",
    "xecon_mol = np.array([0,3,10,50,100,300]) / 3.3\n",
    "Distance = 0.93\n",
    "Ntot = 1\n",
    "kx = kxarr\n",
    "yAllarr = np.zeros((len(kI_values), len(xecon_mol)))  # 2D array to store yAll values\n",
    "\n",
    "for i in range(0,len(xecon_mol)):\n",
    "    for idx, kI in enumerate(kI_values):\n",
    "        for j in range(0,len(Type) - 1):\n",
    "            if Type[j] == 'S':\n",
    "                yAllS = Lxekx(xecon_mol[i], Type[j], Distance, Ntot, kI, kx[i]) * constants[\"PDE128\"]\n",
    "            elif Type[j] == 'T':\n",
    "                yAllT = Lxekx(xecon_mol[i], Type[j], Distance, Ntot, kI, kx[i]) * constants[\"PDE128\"]\n",
    "            elif Type[j] == 'M':\n",
    "                yAllM = Lxekx(xecon_mol[i], Type[j], Distance, Ntot, kI, kx[i]) * constants[\"PDE150\"]\n",
    "            elif Type[j] == 'X':\n",
    "                yAllX = Lxekx(xecon_mol[i], Type[j], Distance, Ntot, kI, kx[i]) * constants[\"PDE175\"]\n",
    "            else:\n",
    "                PDE = -2000\n",
    "        \n",
    "        yAll = yAllS + yAllT + yAllM + yAllX\n",
    "        \n",
    "        yAllarr[idx, i] = yAll\n",
    "\n",
    "# Normalize each function by its respective value at xecon_mol[5]\n",
    "norm_vals = yAllarr[:, 5]\n",
    "yAllarr_normalized = yAllarr / norm_vals[:, np.newaxis]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7, 3))\n",
    "\n",
    "colormap = plt.get_cmap(\"viridis\", len(kI_values))\n",
    "\n",
    "for idx, kI in enumerate(kI_values):\n",
    "    color = colormap(idx)\n",
    "    label = f\"kI={kI:.5f}\"\n",
    "    ax1.plot(xecon_mol, yAllarr_normalized[idx, :], \".\", color=color, label=label)\n",
    "    ax2.plot(xecon_mol_log, yAllarr_normalized[idx, :], \".\", color=color, label=label)\n",
    "#legend1 = ax1.legend(fontsize=9, ncol=2)\n",
    "TwoPlots(Xe_mol_label, pe_label, \"no\", \"no\", 2, Xe_g_label, \"no\", Xe_mol_label, pe_label, \"log\", \"no\", 2, Xe_g_label, \"log\", \"Leibelt_pey_dipkI\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
